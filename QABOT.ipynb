{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUcFn4Wxxl1jmajkQGjbzm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritish-02/Book-recommendation/blob/main/QABOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJA5Vr87NK2w",
        "outputId": "ef3c3c76-730e-4c3c-929c-ec3b79a9ce11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.7.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/224.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.0 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KQb4ssONAhj",
        "outputId": "aba3bca1-66ff-43f4-cd61-79c54e4863fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required modules"
      ],
      "metadata": {
        "id": "MPRIxe-InBM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yuIJZyt0M8Wb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "from time import time,sleep\n",
        "from uuid import uuid4\n",
        "import datetime\n",
        "import pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Handling\n"
      ],
      "metadata": {
        "id": "d10fwON3l9Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "\n",
        "def load_json(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return json.load(infile)\n",
        "\n",
        "\n",
        "def save_json(filepath, payload):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(payload, outfile, ensure_ascii=False, sort_keys=True, indent=2)\n",
        "\n",
        "\n",
        "def timestamp_to_datetime(unix_time):\n",
        "    return datetime.datetime.fromtimestamp(unix_time).strftime(\"%A, %B %d, %Y at %I:%M%p %Z\")"
      ],
      "metadata": {
        "id": "rEykyv-Ul2B3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For embedding the openai model"
      ],
      "metadata": {
        "id": "EE3VUOcYmQdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gpt3_embedding(content, engine='text-embedding-ada-002'):\n",
        "    content = content.encode(encoding='ASCII',errors='ignore').decode()  # fix any UNICODE errors\n",
        "    response = openai.embeddings.create(input=content,model=engine)\n",
        "    vector = response.data[0].embedding # this is a normal list\n",
        "    return vector"
      ],
      "metadata": {
        "id": "tdFKoDXfN_q5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For completion of the responses"
      ],
      "metadata": {
        "id": "9oQDABddmgMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt3_completion(prompt, engine='text-davinci-ada-003', temp=0.0, top_p=1.0, tokens=400, freq_pen=0.0, pres_pen=0.0, stop=['USER:', 'qabot']):\n",
        "    max_retry = 5\n",
        "    retry = 0\n",
        "    prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = openai.completions.create(\n",
        "                model=engine,\n",
        "                prompt=prompt,\n",
        "                temperature=temp,\n",
        "                max_tokens=tokens,\n",
        "                top_p=top_p,\n",
        "                frequency_penalty=freq_pen,\n",
        "                presence_penalty=pres_pen,\n",
        "                stop=stop)\n",
        "            text = response['choices'][0].text.strip()\n",
        "            text = re.sub('[\\r\\n]+', '\\n', text)\n",
        "            text = re.sub('[\\t ]+', ' ', text)\n",
        "            filename = '%s_gpt3.txt' % time()\n",
        "\n",
        "            if not os.path.exists('gpt3_logs'):\n",
        "                os.makedirs('gpt3_logs')\n",
        "\n",
        "            save_file('gpt3_logs/%s' % filename, prompt + '\\n\\n==========\\n\\n' + text)\n",
        "            return text\n",
        "        except Exception as oops:\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                return \"GPT3 error: %s\" % oops\n",
        "            print('Error communicating with OpenAI:', oops)\n",
        "            sleep(1)"
      ],
      "metadata": {
        "id": "1SMfTsh0mdce"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loading the conversations"
      ],
      "metadata": {
        "id": "ooDj3tI_mr3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_conversation(results):\n",
        "    result = list()\n",
        "    for m in results['matches']:\n",
        "        info = load_json('/content/nexus/%s.json' % m['id'])\n",
        "        result.append(info)\n",
        "    ordered = sorted(result, key=lambda d: d['time'], reverse=False)  # sort them all chronologically\n",
        "    messages = [i['message'] for i in ordered]\n",
        "    return '\\n'.join(messages).strip()"
      ],
      "metadata": {
        "id": "c8XDoxEimnoh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver code"
      ],
      "metadata": {
        "id": "vT2cUGDNm7Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    convo_length = 30\n",
        "    openai.api_key = open_file('/content/key_openai.txt')\n",
        "    pinecone.init(api_key=open_file('/content/key_pinecone.txt'), environment='gcp-starter')\n",
        "    vdb = pinecone.Index(\"qabot\")\n",
        "    while True:\n",
        "        #### get user input, save it, vectorize it, save to pinecone\n",
        "        payload = list()\n",
        "        a = input('\\n\\nUSER: ')\n",
        "        timestamp = time()\n",
        "        timestring = timestamp_to_datetime(timestamp)\n",
        "        #message = '%s: %s - %s' % ('USER', timestring, a)\n",
        "        message = a\n",
        "        vector = gpt3_embedding(message)\n",
        "        unique_id = str(uuid4())\n",
        "        metadata = {'speaker': 'USER', 'time': timestamp, 'message': message, 'timestring': timestring, 'uuid': unique_id}\n",
        "        save_json('nexus/%s.json' % unique_id, metadata)\n",
        "        payload.append((unique_id, vector))\n",
        "        #### search for relevant messages, and generate a response\n",
        "        results = vdb.query(vector=vector, top_k=convo_length)\n",
        "        conversation = load_conversation(results)  # results should be a DICT with 'matches' which is a LIST of DICTS, with 'id'\n",
        "        prompt = open_file('/content/prompt.txt').replace('<<conversation>>', conversation).replace('<<message>>', a)\n",
        "        #### generate response, vectorize, save, etc\n",
        "        output = gpt3_completion(prompt)\n",
        "        timestamp = time()\n",
        "        timestring = timestamp_to_datetime(timestamp)\n",
        "        #message = '%s: %s - %s' % ('QABOT', timestring, output)\n",
        "        message = output\n",
        "        vector = gpt3_embedding(message)\n",
        "        unique_id = str(uuid4())\n",
        "        metadata = {'speaker': 'QA', 'time': timestamp, 'message': message, 'timestring': timestring, 'uuid': unique_id}\n",
        "        save_json('nexus/%s.json' % unique_id, metadata)\n",
        "        payload.append((unique_id, vector))\n",
        "        vdb.upsert(payload)\n",
        "\n",
        "        print('\\n\\nQABOT: %s' % output)"
      ],
      "metadata": {
        "id": "PDSIEV-ymuiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHKuD-KInMy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}